# P5 Markov Chain exemples

## Exemple 1 : One dimensional chain

This exemple uses a serie fucntion transitionning between three states, without probability distribution.  
It falls back into the structure of a serie repetition such as 1, 2, 3 ; 1, 2, 3 : ...

## Exemple 2 : Simplified Markov

This exemple begins with an array of probability, a matrix that indicates with wich probability each state will transition to each of the states.  
The exemple is based on three states, therefore a square matrix of size 3, containing 9 values. The sum of each line of the matrix must be equal to 1.
