# P5 Markov Chain exemples

Markov chains are statistical (stochastic) models dealing with states following each others according to probability distribution.

## Exemple 1 : One dimensional chain

This exemple uses a serie function transitionning between three states, without probability any distribution.  
It falls back into the structure of a serie repetition such as 1, 2, 3 ; 1, 2, 3 : ...

[run in the borwser](http://mobitool.free.fr/edu/ma-ex1.html)

## Exemple 2 : Simplified Markov

This exemple begins with an array of probability, a matrix that indicates with wich probability each state will transition to each of the states (including the current one).  
The exemple is based on three states, therefore a square matrix of size 3, containing 9 values. The sum of each line of the matrix must be equal to 1.

[run in the borwser](http://mobitool.free.fr/edu/ma-ex2.html)
